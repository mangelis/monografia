%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---------------------------------------------------------------------------------  %
% ---------------------------------------------------------------------------------  %
%                                                                                    %
%                  MODELO DE MONOGRAFIA DO E-COMP - POLI - UPE                       %
%                                                                                    %
% ---------------------------------------------------------------------------------  %
% ---------------------------------------------------------------------------------  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Referencial Teórico \label{cap:referencial} }
\section{Grafos}
Um grafo $\mathcal{G=(V,E)}$ é definido por um conjunto $\mathcal{V=}$$\{v_1,v_2, \ldots,v_n\}$ de vértices 
e por um conjunto $\mathcal{E=}$$\{e_1,e_2, \ldots,e_m\}$ de arestas tais que $\mathcal{E \subseteq V \times V }$
e $\mathcal{V \cap E = \emptyset}$. Eles podem ser direcionados (figura \ref{fig:grafo_direcionado_ponderado}) ou não (figura \ref{fig:grafo_nao_direcionado_simples}) No primeiro caso, suas arestas são pares
ordenados de vértices, já no segundo, a ordem é indiferente. Além disso, valores numéricos podem ser associados
a cada aresta. Se este for o caso, o grafo é denominado ponderado. Um caminho de comprimento $L$ é uma sequência
alternada $v_{1}e_{1}v_{2}e_{2}v_{3} \ldots v_{L-1}e_{L-1}v_{L}$ de vértices $v_{i}$ e arestas $e_{i}$ de forma que
o vértice de destino de $e_{i}$ é $v_{i}$, e seu vértice de destino, $v_{i+1}$. Um cíclo é um caso particular de caminho onde $v_{1}=v_{L}$. Diz-se que um grafo é conectado quando existe ao menos um caminho conectando todos os pares de vértices.

\begin{figure}[htpb]
	\begin{center}
		\includegraphics[width=180pt]{imagens/grafo_simples.png}
		\textbf{
			\caption{
				Exemplo de grafo não direcionado simples.
			}
			\label{fig:grafo_nao_direcionado_simples}
		}
		\footnotesize{[Fonte: reproduzido de \text{http://graphml.graphdrawing.org/primer/simple.png}]}
	\end{center}
\end{figure}

\begin{figure}[htpb]
	\begin{center}
		\includegraphics[width=180pt]{imagens/grafo_direcionado_ponderado.png}
		\textbf{
			\caption{
				Exemplo de grafo direcionado ponderado.
			}
			\label{fig:grafo_direcionado_ponderado}
		}
		\footnotesize{[Fonte: reproduzido de \text{http://www.hipster4j.org/assets/css/custom/img/graph-example-hipster-blue.png}]}
	\end{center}
\end{figure}

\par
Um grafo $\mathcal{G}$ com $n$ vértices pode ser representado por uma matriz $\mathcal{A}=\left[a_{ij}\right]$ $n \times n$ como segue:

\begin{gather}
	a_{ij} =
		\begin{cases}
			w_{ij} & \text{se existe uma aresta de } v_{i} \text{ para } v_{j} \\
			0 & \text{caso contrário }
		\end{cases} 
	\intertext{Onde:}
	\begin{tabular}{>{$}r<{$}@{\ :\ }l}
		w_{ij} & é o peso da aresta entre os vértices $v_{i}$ e $v_{j}$
	\end{tabular}\nonumber
\end{gather}

\par
Vértices podem ser nomeados de diversas maneiras: nós, pontos, agentes, etc. Arestas também: ligações, 

\section{Redes Complexas}
A pesquisa em redes complexas pode ser definida como a intersecção entre a teoria dos grafos e a mecânica estatística, 
o que lhe garante uma forte natureza interdisciplinar \cite{luciano_2005_characterization}. 
Por muito, se pensou que os relacionamentos entre vértices eram representados por padrões aleatórios, e um importantíssimo modelo de formação de grafos aleatórios foi proposto \cite{erdos_evolution_random_graphs}. Contudo, foi descoberto que as redes reais não se comportam como redes aleatórias, mas sim como explicado em importantes modelos, como os livres de escala \cite{barabasi_2007_scale_free_random} e os de redes \emph{small-world} \cite{watts_1998_small_world}.  

\par
Podem ser mencionados dois importantes motivos para a popularidade das redes complexas:
\begin{enumerate}
	\item grande parte dos sistemas complexos são modelados por sistemas de equações diferenciais cuja solução analítica é praticamente impraticavel;
	\item as redes complexas apresentam grande flexibilidade e poder de generalização para representar virtualmente qualquer estrutura natural, incluindo aquelas dotadas de mudanças topológicas dinâmicas \cite{luciano_2005_characterization}
\end{enumerate}

\begin{figure}[htpb]
	\begin{center}
		\includegraphics[width=360pt]{imagens/redes_amigos_cor.png}
		\textbf{
			\caption{Rede de amizades de crianças em uma escola dos EUA. Trata-se de um grafo direcionado pois uma criança $A$ pode alegar ser amiga de outra criança $B$, mas não necessariamente o inverso. Os vértices são coloridos em função da cor da pele. A divisão horizontal da rede reflete o distanciamento entre indivíduos de etnias diferentes, enquanto a vertical remete à faixa etária.}
			\label{fig:rede_amizade_cor}
		}
		\footnotesize{[Fonte: \cite{newman_structure_function_cn}]}
	\end{center}
\end{figure}

\par
Redes complexas têm sido estudas e aplicadas em várias de áreas da ciência \cite{wang_2008_cn_small_world_beyond}. Dentre as várias redes reais amplamente estudas estão:
\begin{enumerate}
	\item a internet: rede de computadores e roteadores de proporções colossais (figura \ref{fig:rede_internet});
	\item o cérebro humano \cite{brain_bullmore_olaf} \cite{olaf_book_brain_networks};
	\item redes de interação de proteínas;
	\item redes sociais (figura \ref{fig:rede_amizade_cor});
	\item redes de transmissão elétrica
\end{enumerate}


\begin{figure}[htpb]
	\begin{center}
		\includegraphics[width=360pt]{imagens/internet.png}
		\textbf{
			\caption{Visualização da estrutura da rede da internet. Cada nó é um "sistema autônomo" (grupos locais de computadores, cada um representando centenas ou milhares de máquinas.}
			\label{fig:rede_internet}
		}
		\footnotesize{[Fonte: \cite{newman_structure_function_cn}]}
	\end{center}
\end{figure}

\subsection{Métricas de redes complexas} 
Medidas estrurais são frequentemente utilizadas para capturar informações topológicas acerca da rede. Existem miríades delas.
Esta monigrafia utiliza algumas métricas que se mostraram potencialmente úteis na tarefa de distinguir traços estilísticos de textos em outros trabalhos \cite{amancio_2015_complex_network_approach_stylometry}\cite{amancio_2011_comparing_intermittency}\cite{amancio_2012_literary_movements}\cite{amancio_2015_flunctuation}\cite{amancio_phd}.
Outras medidas também foram utilizadas, pois conceitualmente capturam características de centralidade com eficácia.

\subsubsection{Grau e força}
O grau é uma simples e importante medida de centralidade. Ele pode ser assim classificado, pois vértices que apresentam altos valores de grau são mais importantes (centrais) para a rede. O grau de um vértice $i$, denotado por $k_{i}$ é o número de arestas associadas a esse vértice. Para grafos não direcionados, seu valor pode ser obtido por
\begin{equation}
\label{eq:grau_grafo_nao_direcionado}
k_{i} = \sum_{j}a_{ij}
\end{equation}

\par
O grau médio de uma rede é a média dos valores de $k_{i}$ para todos os seus nós
\begin{equation}
\label{eq:grau_medio_grafo_nao_direcionado}
\langle k \rangle = \frac{1}{N}\sum_{i}k_{i}
\end{equation}
Para redes representadas por grafos direcionados, há dois tipos de grau: o grau de saída, que representa a quantidade de arestas que partem de um vértice, e o grau de entrada, que corresponde ao número de arestas que tem o vértice em questão como destino. O grau total é definido como a soma dos dois anteriores
\begin{equation}
\label{eq:grau_saida_direcionado}
k_{i}^{saída} = \sum_{j}a_{ij}
\end{equation}
\begin{equation}
\label{eq:grau_entrada_direcionado}
k_{i}^{entrada} = \sum_{j}a_{ji}
\end{equation}
\begin{equation}
\label{eq:grau_total_direcionado}
k_{i} = k_{i}^{saída} + k_{i}^{entrada}
\end{equation}

\par
As médias de graus de entrada e saídas são as mesmas para redes conectadas.
\begin{equation}
\label{eq:grau_medio_grafo_direcionado}
\langle k^{saída} \rangle = \langle k^{entrada} \rangle = \frac{1}{N}\sum_{i}k_{i}
\end{equation}

\par
As definições acima mencionadas podem ser extendidas para grafos ponderados, mas frequentemente uma outra medida, chamada \emph{strength} (força), é empregada. Ela é definida pelas seguintes expressões:
\begin{equation}
\label{eq:grau_saida_direcionado_ponderado}
s_{i}^{saída} = \sum_{j}w_{ij}
\end{equation}
\begin{equation}
\label{eq:grau_entrada_direcionado_ponderado}
s_{i}^{entrada} = \sum_{j}w_{ji}
\end{equation}

\par
Essa métrica pode ser empregada em redes de citações, para verificar o número de citações recebidas por um artigo científico, ou em redes sociais, onde representa o grau de influência do indivíduo \cite{amancio_phd}.

\subsubsection{Caminho mínimo médio}
\label{subsubsection:caminho_minimo_medio}
Sendo dist$(i,j)$ o comprimento do menor caminho que liga o vértice $v_{i}$ ao vértice $v_{j}$, o comprimento médio dos caminhos iniciados por $v_{i}$ pode ser expressado como
\begin{equation}
	\label{eq:comprimento_medio}
	L_{i} = \frac{1}{M-1}\sum_{j=1}^{M}\text{dist}(i,j)
\end{equation}
Deve-se atentar para que dist$(i,i) = 0$, logo o denominador não deve ser o número total de vértices presentes na rede, mas sim esse número subtraído em uma unidade. Outra definição importante é o diâmetro da rede
\begin{equation}
	\label{eq:diametro}
	d = \text{max dist}(i,j)
\end{equation}

\par
De acordo com \cite{amancio_phd}, mesmo o menor caminho médio não sendo correlacionado com a frequência com que uma palavra aparece no texto, 
vocábulos com altos valores de $L$ aparecem pouco frequentemente.

\par
Os grafos tratados neste trabalho são direcionados e ponderados, logo a distância entre dois vértices é a soma dos pesos das arestas que compõem o caminho entre eles.

\par
 Tradicionalmente, para grafos sem arestas múltiplas, o peso de uma aresta representa o número de vezes seus vértices aparecem conectados. No presente trabalho, contudo, os pesos das areastas foram invertidos:
 \begin{equation}
	\label{eq:pesos_invertidos}
	w_{ij}^{novo} = \frac{1}{w_{ij}^{antigo}}
 \end{equation}
 
 Assim foi decido, pois no modelo construído para este trabalho, dois nós que frequentemente aparecem conectados devem ser considerados próximos.
 
\subsubsection{Coeficiente de Aglomeração (\emph{Clustering Coefficient})}
O coeficiente de clusterização (\emph{clustering coefficient}) $C$ quantifica o quão próximo de um clique (grafo totalmente conectado) é o subgrafo composto pelos vizinhos de um nó. Esta é uma medida frequentemente utilizada no estudo de redes sociais e, nesse cenário, pode ter seu significado exemplificado pela frase: "quantos amigos de meus amigos são amigos entre si?" Vértices que apresentam máximos valores de $C$ satisfazem a transitividade de vizinhos, ou seja, se dois vértices $v_{i}$ e $v_{j}$ são vizinhos de $v_{k}$, estão eles também estão conectados entre si. Percebe-se que esta metríca não pode ser definida para vértices que não possuem pelo menos 2 vizinhos. Então, se $\Psi_{i}$ é a quantidade de arestas entre os vizinhos de $v_{i}$, esse vértice tem seu coeficiente de aglomeração $C_{i}$ definido por
\begin{equation}
	\label{eq:coeficiente_aglomeracao}
	C_{i} =
	\begin{cases}
	2\Psi_{i}/(k_{i}^{2} - k_{i}) & \text{para } k_{i} > 1,\\
	0 & \text{para }  k_{i} \leq 1
	\end{cases} 
\end{equation}

\par
De acordo com \cite{amancio_2011_comparing_intermittency}, palavras com altos valores de coeficiente de aglomeração tem maior probabilidade de aparecer em contextos mais restritos. Ou seja, valores relativamente baixos de $C$ caracterizam palavras que aparecem em uma grande gama de contextos, explicando assim porque seus vizinhos são relativamente pouco conectados. Deve-se atentar para que $C$ é uma medida de centralidade local, isto é, para o seu cálculo são necessários apenas os nós vizinhos àquele que se tem interesse.


\subsubsection{\emph{Betweenness}}
O \emph{betweenness} ($B$) é uma medida de de centralidade que foi proposta \cite{freeman_betweenness}. Esta métrica considera que um vértice é importante se esse é acessado por um grande número de caminhos mínimos. Vértices com altos valores de \emph{betweenness} têm grande influência na rede, pois distribuem a informação pelo grafo. Por isso, em redes de sistemas de comunicação, esses vértices são os que cuja remoção mais impacta na comunicação entre outros vértices. \cite{newman_book_networks_intro}. Caso haja mais de um caminho entre dois vértices, o \emph{betweenness} será divido igualmente para todos. Desta forma, se existem $n_{L}$ caminhos mínimos entre dois nós, cada um desses terá seu \emph{betweenness} ponderado por $n_{L}^{-1}$. Assim como feito em \cite{amancio_phd}, neste trabalho o \emph{betweenness} será calculado de modo a evitar correlações com outras métricas. Sendo $\eta_{sit}$ o número de caminhos mínimos de $v_{s}$ a $v_{t}$ que passam por $v_{i}$, e $\eta_{st}$ o número de caminhos geodésicos que partem de $v_{s}$ para $v_{t}$, o \emph{betweenness} pode ser definido como
\begin{equation}
	\label{eq:betweenness}
	B_{i}=\frac{1}{M^{2}}\sum_{s=1}^{M}\sum_{t=1}^{M}\frac{\eta_{sit}}{\eta_{st}}
\end{equation}
Majoritariamente, no contexto de análise textual, as palavras que apresentam altos valores de \emph{betweenness} são aquelas com alta frequência, e também algumas que conectam comunidades de conceitos relacionados.

\par
\cite{amancio_2011_comparing_intermittency} sugere que vocábulos com altos valores de $B$ ligam conceitos de comunidades semânticas distintas porque têm alta probabilidade de aparecerem em vários contextos. Similarmente como faz o coeficiente de agloremeração $C$, o \emph{betweenness} também representa a variedade de contextos que uma palavra pode aparecer, embora esse se baseie em padrões de conectividade globais, enquanto o primeiro, em padrões locais.

\par
Os valores de \emph{betweenness} calculados nos grafos gerados nesta monografia diferem daqueles gerados por \cite{amancio_phd} pois, como dito na seção \ref{subsubsection:caminho_minimo_medio}, os valores dos pesos das arestas foram redefinidos.


\subsubsection{Assortatividade de Grau}
Muito frequentemente é desejável saber se as ligações de uma rede são estabelecidas preferencialmente entre vértices pertencentes a uma mesma classe ou entre aqueles de classes distintas. Pensando nisso, a assortatividade foi proposta em \cite{newman_2002_assortativity}. Nete trabalho, foi utilizada a assortatividade de grau, ou seja, aquela que tem objetivo determinar se as ligações de um dado vértice são correlacionadas com o seu grau e de seus vizinhos. Um dos modos de definir matematimente esta correlação é por meio de probabilidades condicionais. Sendo $P(k,k^{'})$ a probabilidade de uma aresta conectar vértices com graus $k$ e $k^{'}$, a probilidade condicional de que um vértice com grau $k$ esteja conectado com um de grau $k_{'}$ é dada pela expressão:
\begin{equation}
	\label{eq:assortatividade_prob_condicional}
	P(k^{'}|k) = \frac{\langle k \rangle P(k,k^{'})}{kP(k)}
\end{equation}
Contudo, a equação mais utilizada é aquela proposta no artigo que definiu a assortatividade:
\begin{equation}
	\label{eq:assortatividade_newman}
	r = \frac{M^{-1}\sum_{i}j_{i}k_{i} - [M^{-1}\sum_{i}\frac{1}{2}(j_{i}+k_{i})]^{2}}
	{M^{-1}\sum_{i}\frac{1}{2}(j_{i}^{2}+k_{i}^{2}) - [M^{-1}\sum_{i}\frac{1}{2}(j_{i}+k_{i})]^{2}}
\end{equation}

A rede é chamada não assortativa quando $r < 0$, isto é, vértices de graus baixos tendem a se conectar a outros nós de graus baixos. Quando $r > 0$, nós com elevados graus têm maiores chances de se conectarem a outros nós com altos valores de grau. Neste último caso, a rede é dita assortativa. 

\subsubsection{\emph{PageRank}}
O \emph{Pagerank} também é uma medida de centralidade e foi proposta em \cite{page_rank}. Ela é usada como uma das principais técnicas usadas no Google para mensuração da relevância de páginas \emph{web} em buscas feitas por usuários cotidianamente. Está técnica pode ser vista como um avanço à centralidade de Katz \cite{katz_centrality} \cite{newman_book_networks_intro}. A centralidade de Katz, como outras medidas dessa natureza, mede a influência de um nó na rede. Nessa métrica, o seu valor numérico não é de todo relevante, entretanto a informação útil está na identificação dos vértices que apresentam de centralidade altos ou baixos. Vértices com alta centralidade de Katz são acessíveis por vários outros nós. Todavia, um dos pontos negativos da centralidade de Katz é que se um nó com com alta centralidade têm um grande número de vizinhos, esses nós também apresentarão alta centralidade. O \emph{Pagerank} pondera essa redistribição de relevância na rede e matematicamente pode ser definido como
\begin{equation}
	\label{eq:pagerank}
	\textbf{x}=\textbf{D}(\textbf{D} - \alpha\textbf{A})^{-1}\textbf{1}
\end{equation}
onde \textbf{1} é o vetor $(1,1,1,\dots)$, \textbf{D} é a matriz diagonal com elementos $D_{ij}=\text{max}(k_{i}^{out},1)$, e \textbf{x}, o vetor de centralidades. Com a reponderação de importância, o \emph{Pagerank} permite que apenas os reais nós centrais tenham valores elevados de centralidade.
 

\section{Processamento de Texto}
\subsection{\emph{Part-of-Speech tagging}}
\emph{Part-of-Speech tagging} é a tarefa de rotular palavras em um texto de acordo com sua classe gramatical
(substantivo, adjetivo, verbo, artigo, etc). Como muitas palavras, nas mais diversas línguas, são passíveis de 
serem classificadas em mais de uma categoria, o processo de rotulação torna-se ambíguo. Nesta monografia, foi
utilizado o \emph{part-of-Speech tagger} desenvolvido pela Universidade de Stanford \cite{stanford_nlp_core}
\cite{stanford_2000_pos_tagger}\cite{stanford_2003_pos_tagger}.

\section{Tipos de Redes Textuais}
A seguir, os três tipos de redes mais utilizados para modelar textos são expostas.

\subsection{Redes de co-ocorrência}
A forma mais natural de associar palavras é pela conexão de palavras vizinhas, pois a linguagem escrita
é composta por cadeiras lineares de palavras. Isso faz deste tipo de rede textual um dos mais empregados na literatura
\cite{cancho_2001_small_world_language} \cite{amancio_2015_flunctuation}\cite{amancio_2015_complex_network_approach_stylometry}\cite{amancio_phd}. 
Os grafos gerados podem ser direcionados ou não. A ordem das palavras pode refletir parcialmente nas relações
sintáticas e semânticas entre elas.\cite{sole_language_networks}. Se houver \emph{stopwords} (palavras de baixo valor 
semântico, contudo de grande importância gramatical) no texto, essas palavras serão \emph{hubs} na rede. Outras duas importantes
características das redes de co-ocorrência de palavras é que elas são livres de escala e apresentam o comportamento \emph{small-world}
\cite{amancio_phd}.

\begin{figure}[htpb]
	\begin{center}
		\includegraphics[width=360pt]{imagens/co-occurrence-sally-amancio.jpg}
		\textbf{
			\caption{
				Grafo não orientado obtido a partir da sentença "What's that? Asked Sally. 
				Pay my bill for last week, due this morning. Sally got up quickly, and flitting 
				down the table, put her arm round her friend's shoulder and whispered in her ear."  
				do livro "The Adventures of Sally" de P.G. Wodehouse.
			}
			\label{fig:co-occurrence-sally-amancio}
		}
		\footnotesize{[Fonte: \cite{amancio_phd}]}
	\end{center}
\end{figure}

\subsection{Redes Sintáticas}
As redes sintáticas associam as palavras que apresentam dependência sintática entre si.
Essas dependências podem ser trazidas à tona por meio das gramáticas de dependências. Esse
formalismo é capaz de definir a estrutura sintática de uma sentença como uma árvore. Os \emph{hubs}
neste tipo de rede são palavras funcionais, mas seus graus de entrada e saída são diferentes da
rede anterior \cite{sole_language_networks}. Entretanto, 90\% das conexões das redes sintáticas também
ocorrem nas redes de co-ocorrência \cite{amancio_phd}. Pode-se interpretar então que as redes de
co-ocorrência são aproximações das redes sintáticas. Um outro fato que corrobora esta ideia é que
a rede em questão também apresenta, como a anterior, propriedades livre de escala e \emph{small-world}.

\subsection{Redes Semânticas}
Redes semânticas podem ser construídas a partir de palavras que representam conceitos e associando-as
se se possuírem alguma relação semântica básica como, por exemplo, "é-um", "parte-todo" ou "oposição binária"
\cite{sigman_2002_organization_wordnet}\cite{sole_language_networks}. Também foi verificado que essas redes apresentam uma organização altamente eficiente e que os \emph{hubs} representam palavras polissêmicas \cite{sole_language_networks}. Comumente, as redes semânticas apresentam um alto coeficiente de clusterização. Essa característica permite que buscas por associação sejam feitas rapidamente \cite{motter_2003_topology_net_lang}.

\section{Perceptron de Múltiplas Camadas}
As redes neurais Perceptron de Múltiplas Camadas são aproximadores de funções conexionistas. São formadas por neurônios (unidades de processamento inspirados nas células homônimas) interconectados e divididos em camadas. Para cada um desses componentes, há uma função de ativação (em muitos casos, não linear) que serão responsáveis pela resposta do neurônio para dados estímulos (entradas).
MLPs apresentam um bom poder de generalização e seu conhecimento é armazenado como pesos de cada ligação entre neurônios de camadas distintas \cite{meuser_rna}.

\par
Seu modelo de aprendizado é supervisionado. Isso significa que durante a fase de treinamento, devem ser apresentadas à rede as entradas e suas respectivas saídas. Para cada exemplo apresentado, os parâmetros internos (pesos de cada conexão) são ajustados em função do erro encontrado e do estado atual desses mesmos parâmetros. Após o treinamento, os sinais são propagados apenas no sentido das entradas para as saídas. Por este motivo, as MLPs são classificadas como redes \emph{feedforward}.

\begin{figure}[htpb]
	\begin{center}
		\includegraphics[width=360pt]{imagens/rede_neural_ff_modificada.png}
		\textbf{
			\caption{
				MLP com 1 camada escondida.
			}
			\label{fig:rede_neural}
		}
		\footnotesize{[Fonte: modificada de \cite{felipe_farias_mestrado}]}
	\end{center}
\end{figure}

A arquitetura das MLPs (figura \ref{fig:rede_neural}) deve apresentar os seguintes constituintes:
\begin{enumerate}
	\item Uma camada de entrada: nesta camada estão presentes os neurônios que sofreram os estímulos externos (entradas);
	\item $n$ camadas escondidas: está é a origem da não linearidade das MLPs. Tipicamente possuem funções de ativação não lineares, sendo exemplos clássicos a sigmóide logística e a tangente hiperbólica. Em \cite{haykin_rna} é mostrado que, com uma camada escondida, a rede é capaz de aproximar qualquer função contínua, e, que com duas, qualquer função. Entretanto o número de camadas não deve ser arbritariamente grande, pois para muitos algoritmos de treinamento, as taxas de erro podem aumentar \cite{prechelt_benchmark_rna};
	\item Uma camada de saída: representam a saída da rede. Geralmente são utilizadas funções \emph{softmax} (função que generaliza as sigmóides) para problemas de classificação, mas também podem ser simples funções lineares.
\end{enumerate}

\par
Existem vários algoritmos de treinamento para MLPs. Um dos mais conhecidos e utilizados é o \emph{backpropagation}. Nessa técnica de treinamento, geralmente é utilizado o método de otimização gradiente descendente. De acordo com \cite{meuser_rna}, o\emph{backpropagation} é constituído por duas fases:
\begin{enumerate}
	\item Os sinais de entrada são propagados em direção à saída da rede. Ao alcançar a última camada, a saída é calculada e o erro a ela atribuído;
	\item O erro calculado na etapa anterior é propagado de volta para a entrada. Nesta travessia, é calculada a contribuição de cada neurônio para o erro, e seu peso é ajustado em função disso. A equação de atualização dos pesos também de acordo com \cite{haykin_rna} é:
\end{enumerate}

\begin{equation}
	\label{eq:atualizar_pesos_rna}
	w_{ij}^{m}(t+1) = w_{ij}^{m}(t) + 
	\alpha \delta_{i}^{m}f^{m-1}(net_{j}^{m-1}) +
	\beta \Delta w_{ij}^{m}(t-1),
\end{equation}

onde $\alpha$ é a taxa de aprendizagem, $\beta$ é a taxa de momento, $\delta$ é a sensibilidade que pode ser calculada de acordo com as equações \ref{eq:sensibilidade_entradas_backpropagation} e \ref{eq:sensibilidade_outras_backpropagation} para a camadas de entrada e as demais respectivamente:

\begin{equation}
	\label{eq:sensibilidade_entradas_backpropagation}
	\delta_{i}^{m}=(d_{i} - y{i})f^{'}(net_{i})
\end{equation}

\begin{equation}
	\label{eq:sensibilidade_outras_backpropagation}
	\delta_{i}^{m-1}=f^{'(m-1)}(net_{j}^{m-1})
		\sum_{i=l}^{N}w_{ij}^{m} \delta_{i}^{m}
\end{equation}